{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/YanickSchraner/rl-on-trains-workshop/blob/main/01_Intro_to_environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htEgy_0rsAJE"
   },
   "source": [
    "# Flatland\n",
    "Docs at: http://flatland-rl-docs.s3-website.eu-central-1.amazonaws.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNiahuRZvMBi"
   },
   "source": [
    "## File structure\n",
    "\n",
    "\n",
    "```\n",
    "├── Notebooks, Readme, packages ..\n",
    "├── agents: RL agents implementation\n",
    "│   ├── curiosity.py\n",
    "│   ├── dqn.py\n",
    "│   ├── per.py\n",
    "│   ├── qlearning.py\n",
    "│   └── random.py\n",
    "├── utils: Helpers to train, test, inspect agents\n",
    "│   ├── fast_tree_obs.py\n",
    "│   ├── logging.py\n",
    "│   ├── rl_helpers.py\n",
    "└── └── utils.py\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First we need to import all libraries and clone external helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "_8g943chw4DC",
    "outputId": "d4df5d38-9f09-41ae-e0d7-74764e3790a3"
   },
   "outputs": [],
   "source": [
    "#@title << Setup Google Colab by running this cell {display-mode: \"form\"}\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone --single-branch --branch main https://github.com/YanickSchraner/rl-on-trains-workshop\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"rl-on-trains-workshop/agents\" \"rl-on-trains-workshop/utils\" .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"rl-on-trains-workshop/requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NDRIB0ua04NV"
   },
   "outputs": [],
   "source": [
    "%run utils/fast_tree_obs.py\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "\n",
    "# In Flatland you can use custom observation builders and predicitors\n",
    "# Observation builders generate the observation needed by the controller\n",
    "# Preditctors can be used to do short time prediction which can help in avoiding conflicts in the network\n",
    "\n",
    "# First of all we import the Flatland rail environment\n",
    "from flatland.envs.rail_env import RailEnv, RailEnvActions\n",
    "from flatland.envs.rail_generators import sparse_rail_generator\n",
    "from flatland.envs.schedule_generators import sparse_schedule_generator\n",
    "from flatland.envs.malfunction_generators import MalfunctionParameters, ParamMalfunctionGen\n",
    "\n",
    "# We also include a renderer because we want to visualize what is going on in the environment\n",
    "from flatland.utils.rendertools import RenderTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function to visualize an episode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "def display_episode(frames):\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    imgplot = plt.imshow(frames[0])\n",
    "    def animate(i):\n",
    "        imgplot.set_data(frames[i])\n",
    "    animation = matplotlib.animation.FuncAnimation(fig, animate, frames=len(frames))\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of the RL environment\n",
    "\n",
    "In the next cells we specify the characteristics of our flatland grid and the trains.\n",
    "We use the `FastTreeObs` observation for all of our agents.\n",
    "\n",
    "Training on simple small tasks is the best way to get familiar with the environment.\n",
    "We started by importing the necessary rail and schedule generators.\n",
    "The rail generator will generate the railway infrastructure.\n",
    "The schedule generator will assign tasks to all the agent within the railway network.\n",
    "\n",
    "The railway infrastructure can be build using any of the provided generators in env/rail_generators.py\n",
    "Here we use the sparse_rail_generator with the following parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UlcHBfdR09JI"
   },
   "outputs": [],
   "source": [
    "n_agents = 3 # Number of trains that have an assigned task in the env\n",
    "# Characteristics of the flatland grid:\n",
    "x_dim = 50 # With of map\n",
    "y_dim = 50 # Height of map\n",
    "n_cities = 4 # Number of cities where agents can start or end\n",
    "max_rails_between_cities = 2 # Max number of tracks allowed between cities. This is number of entry point to a city\n",
    "max_rails_in_city = 8 # Max number of parallel tracks within a city, representing a realistic trainstation\n",
    "\n",
    "seed = 42 # Random seed\n",
    "\n",
    "# Custom observation builder\n",
    "tree_observation = FastTreeObs(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule generator can make very basic schedules with a start point, end point and a speed profile for each agent.\n",
    "The speed profiles can be adjusted directly as well as shown later on. We start by introducing a statistical distribution of speed profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different agent types (trains) with different speeds.\n",
    "speed_ration_map = {1.: 0.25,  # Fast passenger train\n",
    "                    1. / 2.: 0.25,  # Fast freight train\n",
    "                    1. / 3.: 0.25,  # Slow commuter train\n",
    "                    1. / 4.: 0.25}  # Slow freight train\n",
    "\n",
    "# We can now initiate the schedule generator with the given speed profiles\n",
    "schedule_generator = sparse_schedule_generator(speed_ration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can furthermore pass stochastic data to the RailEnv constructor which will allow for stochastic malfunctions\n",
    "# during an episode.\n",
    "\n",
    "stochastic_data = MalfunctionParameters(malfunction_rate=1/10000,  # Rate of malfunction occurence\n",
    "                                        min_duration=15,  # Minimal duration of malfunction\n",
    "                                        max_duration=50  # Max duration of malfunction\n",
    "                                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the enviornment with the given observation, generataors, predictors, and stochastic data\n",
    "After creating the environment, we need to call `reset()` to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanick/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/flatland/envs/rail_generators.py:780: UserWarning: Could not set all required cities!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 13)]\n"
     ]
    }
   ],
   "source": [
    "env = RailEnv(width=x_dim,\n",
    "              height=y_dim,\n",
    "              rail_generator=sparse_rail_generator(max_num_cities=n_cities,# Number of cities in map (where train stations are)\n",
    "                                                   seed=seed,  # Random seed\n",
    "                                                   grid_mode=False,\n",
    "                                                   max_rails_between_cities=max_rails_between_cities,\n",
    "                                                   max_rails_in_city=max_rails_in_city,\n",
    "                                                   ),\n",
    "              schedule_generator=schedule_generator,\n",
    "              number_of_agents=n_agents,\n",
    "              malfunction_generator=ParamMalfunctionGen(stochastic_data),\n",
    "              obs_builder_object=tree_observation,\n",
    "              remove_agents_at_target=True,\n",
    "              record_steps=True\n",
    "              )\n",
    "\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RenderTool` allows us to visualize the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5A6tz6vr1Un1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "env_renderer = RenderTool(env, gl=\"PGL\", screen_width=500, screen_height=500, show_debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at the map we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_window - pyglet\n"
     ]
    }
   ],
   "source": [
    "image = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, return_image=True)\n",
    "plt.subplots(figsize=(12,12))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an initial example we create a random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now we can take 500 random steps in our environment and then visualize how the train moved in this episode.\n",
    "class RandomAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        return np.random.choice([RailEnvActions.MOVE_FORWARD, RailEnvActions.MOVE_RIGHT, RailEnvActions.MOVE_LEFT,\n",
    "                                 RailEnvActions.STOP_MOVING])\n",
    "\n",
    "    def step(self, memories):\n",
    "        \"\"\"\n",
    "        Step function to improve agent by adjusting policy given the observations\n",
    "\n",
    "        :param memories: SARS Tuple to be\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Store the current policy\n",
    "        return\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load a policy\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the agent with the parameters corresponding to the environment and observation_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "controller = RandomAgent(218, env.action_space[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by looking at the information of each agent.\n",
    "We can see the task assigned to the agent by looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Agents in the environment have to solve the following tasks: \n",
      "\n",
      "The agent with index 0 has the task to go from its initial position (38, 34), facing in the direction 1 to its target at (23, 10).\n",
      "The agent with index 1 has the task to go from its initial position (23, 13), facing in the direction 2 to its target at (46, 17).\n",
      "The agent with index 2 has the task to go from its initial position (21, 29), facing in the direction 3 to its target at (7, 9).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Agents in the environment have to solve the following tasks: \\n\")\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"The agent with index {} has the task to go from its initial position {}, facing in the direction {} to its target at {}.\".format(\n",
    "            agent_idx, agent.initial_position, agent.direction, agent.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent will always have a status indicating if it is currently present in the environment or done or active.\n",
    "For example we see that agent with index 0 is currently not active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Their current statuses are:\n",
      "============================\n",
      "Agent 0 status is: RailAgentStatus.READY_TO_DEPART with its current position being None\n",
      "Agent 1 status is: RailAgentStatus.READY_TO_DEPART with its current position being None\n",
      "Agent 2 status is: RailAgentStatus.READY_TO_DEPART with its current position being None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Their current statuses are:\")\n",
    "print(\"============================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\"Agent {} status is: {} with its current position being {}\".format(agent_idx, str(agent.status),\n",
    "                                                                             str(agent.position)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent needs to take any action [1,2,3] except do_nothing or stop to enter the level.\n",
    "\n",
    "If the starting cell is free they will enter the level.\n",
    "If multiple agents want to enter the same cell at the same time the lower index agent will enter first.\n",
    "\n",
    "Let's check if there are any agents with the same start location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The following agents have the same initial position:\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "agents_with_same_start = set()\n",
    "print(\"\\n The following agents have the same initial position:\")\n",
    "print(\"=====================================================\")\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    for agent_2_idx, agent2 in enumerate(env.agents):\n",
    "        if agent_idx != agent_2_idx and agent.initial_position == agent2.initial_position:\n",
    "            print(\"Agent {} as the same initial position as agent {}\".format(agent_idx, agent_2_idx))\n",
    "            agents_with_same_start.add(agent_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to enter with all of these agents at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 13)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({0: array([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  1: array([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  2: array([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.])},\n",
       " {0: -0.25, 1: -0.3333333333333333, 2: -0.25},\n",
       " {0: False, 1: False, 2: False, '__all__': False},\n",
       " {'action_required': {0: True, 1: True, 2: True},\n",
       "  'malfunction': {0: 0, 1: 0, 2: 0},\n",
       "  'speed': {0: 0.25, 1: 0.3333333333333333, 2: 0.25},\n",
       "  'status': {0: <RailAgentStatus.READY_TO_DEPART: 0>,\n",
       "   1: <RailAgentStatus.READY_TO_DEPART: 0>,\n",
       "   2: <RailAgentStatus.READY_TO_DEPART: 0>}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dict = dict()\n",
    "\n",
    "for agent_id in agents_with_same_start:\n",
    "    action_dict[agent_id] = 1  # Try to move with the agents\n",
    "\n",
    "# Do a step in the environment to see what agents entered:\n",
    "env.step(action_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current state and position of the agents after all agents with same start position tried to move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This happened when all tried to enter at the same time:\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n This happened when all tried to enter at the same time:\")\n",
    "print(\"========================================================\")\n",
    "for agent_id in agents_with_same_start:\n",
    "    print(\n",
    "        \"Agent {} status is: {} with the current position being {}.\".format(\n",
    "            agent_id, str(env.agents[agent_id].status),\n",
    "            str(env.agents[agent_id].position)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see only the agents with lower indexes moved. \n",
    "As soon as the cell is free again the agents can attempt to start again.\n",
    "\n",
    "You will also notice, that the agents move at different speeds once they are on the rail.\n",
    "The agents will always move at full speed when moving, never a speed inbetween.\n",
    "The fastest an agent can go is 1, meaning that it moves to the next cell at every time step.\n",
    "\n",
    "All slower speeds indicate the fraction of a cell that is moved at each time step.\n",
    "Lets look at the current speed data of the agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The speed information of the agents are:\n",
      "=========================================\n",
      "Agent 0 speed is: 0.25 with the current fractional position being 0.0\n",
      "Agent 1 speed is: 0.33 with the current fractional position being 0.0\n",
      "Agent 2 speed is: 0.25 with the current fractional position being 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n The speed information of the agents are:\")\n",
    "print(\"=========================================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"Agent {} speed is: {:.2f} with the current fractional position being {}\".format(\n",
    "            agent_idx, agent.speed_data['speed'], agent.speed_data['position_fraction']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New the agents can also have stochastic malfunctions happening which will lead to them being unable to move for a certain amount of time steps.\n",
    "The malfunction data of the agents can easily be accessed as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The malfunction data of the agents are:\n",
      "========================================\n",
      "Agent 0 is OK = True\n",
      "Agent 1 is OK = True\n",
      "Agent 2 is OK = True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n The malfunction data of the agents are:\")\n",
    "print(\"========================================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"Agent {} is OK = {}\".format(\n",
    "            agent_idx, agent.malfunction_data['malfunction'] < 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have seen these novel concepts that were introduced you will realize that agents don't need to take\n",
    "an action at every time step as it will only change the outcome when actions are chosen at cell entry.\n",
    "\n",
    "Therefore the environment provides information about what agents need to provide an action in the next step.\n",
    "\n",
    "You can access this in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 13)]\n",
      "\n",
      " The following agents can register an action:\n",
      "========================================\n",
      "Agent 0 needs to submit an action.\n",
      "Agent 1 needs to submit an action.\n",
      "Agent 2 needs to submit an action.\n"
     ]
    }
   ],
   "source": [
    "# Chose an action for each agent\n",
    "for a in range(env.get_num_agents()):\n",
    "    action = controller.act(0)\n",
    "    action_dict.update({a: action})\n",
    "# Do the environment step\n",
    "observations, rewards, dones, information = env.step(action_dict)\n",
    "print(\"\\n The following agents can register an action:\")\n",
    "print(\"========================================\")\n",
    "for info in information['action_required']:\n",
    "    print(\"Agent {} needs to submit an action.\".format(info))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at an episode playing out with random actions performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start episode...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStart episode...\")\n",
    "\n",
    "# Reset the rendering system\n",
    "env_renderer.reset()\n",
    "\n",
    "score = 0\n",
    "# Run episode\n",
    "frame_step = 0\n",
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 13)]\n",
      "Episode: Steps 0\t Score = -0.8333333333333333\n",
      "[(24, 13)]\n",
      "Episode: Steps 1\t Score = -1.6666666666666665\n",
      "[(24, 13)]\n",
      "Episode: Steps 2\t Score = -2.5\n",
      "[(21, 27)]\n",
      "Episode: Steps 3\t Score = -3.3333333333333335\n",
      "[(21, 27)]\n",
      "Episode: Steps 4\t Score = -4.166666666666667\n",
      "[(21, 27)]\n",
      "Episode: Steps 5\t Score = -5.0\n",
      "[(21, 27)]\n",
      "Episode: Steps 6\t Score = -5.833333333333333\n",
      "[(21, 27)]\n",
      "Episode: Steps 7\t Score = -6.666666666666666\n",
      "[(26, 13)]\n",
      "Episode: Steps 8\t Score = -7.499999999999999\n",
      "[(26, 13)]\n",
      "Episode: Steps 9\t Score = -8.333333333333332\n",
      "[(26, 13)]\n",
      "Episode: Steps 10\t Score = -9.166666666666666\n",
      "[(26, 13)]\n",
      "Episode: Steps 11\t Score = -10.0\n",
      "Episode: Steps 12\t Score = -10.833333333333334\n",
      "Episode: Steps 13\t Score = -11.666666666666668\n",
      "Episode: Steps 14\t Score = -12.500000000000002\n",
      "Episode: Steps 15\t Score = -13.333333333333336\n",
      "Episode: Steps 16\t Score = -14.16666666666667\n",
      "Episode: Steps 17\t Score = -15.000000000000004\n",
      "Episode: Steps 18\t Score = -15.833333333333337\n",
      "Episode: Steps 19\t Score = -16.666666666666668\n",
      "Episode: Steps 20\t Score = -17.5\n",
      "Episode: Steps 21\t Score = -18.333333333333332\n",
      "Episode: Steps 22\t Score = -19.166666666666664\n",
      "Episode: Steps 23\t Score = -19.999999999999996\n",
      "Episode: Steps 24\t Score = -20.83333333333333\n",
      "Episode: Steps 25\t Score = -21.66666666666666\n",
      "Episode: Steps 26\t Score = -22.499999999999993\n",
      "Episode: Steps 27\t Score = -23.333333333333325\n",
      "Episode: Steps 28\t Score = -24.166666666666657\n",
      "Episode: Steps 29\t Score = -24.99999999999999\n",
      "Episode: Steps 30\t Score = -25.83333333333332\n",
      "Episode: Steps 31\t Score = -26.666666666666654\n",
      "Episode: Steps 32\t Score = -27.499999999999986\n",
      "Episode: Steps 33\t Score = -28.333333333333318\n",
      "Episode: Steps 34\t Score = -29.16666666666665\n",
      "Episode: Steps 35\t Score = -29.999999999999982\n",
      "Episode: Steps 36\t Score = -30.833333333333314\n",
      "Episode: Steps 37\t Score = -31.666666666666647\n",
      "Episode: Steps 38\t Score = -32.49999999999998\n",
      "Episode: Steps 39\t Score = -33.333333333333314\n",
      "Episode: Steps 40\t Score = -34.16666666666665\n",
      "Episode: Steps 41\t Score = -34.999999999999986\n",
      "Episode: Steps 42\t Score = -35.83333333333332\n",
      "Episode: Steps 43\t Score = -36.66666666666666\n",
      "[(34, 10)]\n",
      "Episode: Steps 44\t Score = -37.49999999999999\n",
      "[(34, 10)]\n",
      "Episode: Steps 45\t Score = -38.33333333333333\n",
      "[(34, 10)]\n",
      "Episode: Steps 46\t Score = -39.166666666666664\n",
      "Episode: Steps 47\t Score = -40.0\n",
      "Episode: Steps 48\t Score = -40.833333333333336\n",
      "Episode: Steps 49\t Score = -41.66666666666667\n",
      "Episode: Steps 50\t Score = -42.50000000000001\n",
      "Episode: Steps 51\t Score = -43.33333333333334\n",
      "Episode: Steps 52\t Score = -44.16666666666668\n",
      "[(31, 41)]\n",
      "Episode: Steps 53\t Score = -45.000000000000014\n",
      "[(31, 41)]\n",
      "[(18, 18)]\n",
      "Episode: Steps 54\t Score = -45.83333333333335\n",
      "[(31, 41)]\n",
      "[(18, 18)]\n",
      "Episode: Steps 55\t Score = -46.666666666666686\n",
      "[(31, 41)]\n",
      "[(18, 18)]\n",
      "Episode: Steps 56\t Score = -47.50000000000002\n",
      "[(18, 18)]\n",
      "Episode: Steps 57\t Score = -48.33333333333336\n",
      "Episode: Steps 58\t Score = -49.16666666666669\n",
      "Episode: Steps 59\t Score = -50.00000000000003\n",
      "Episode: Steps 60\t Score = -50.833333333333364\n",
      "Episode: Steps 61\t Score = -51.6666666666667\n",
      "Episode: Steps 62\t Score = -52.500000000000036\n",
      "Episode: Steps 63\t Score = -53.33333333333337\n",
      "Episode: Steps 64\t Score = -54.16666666666671\n",
      "Episode: Steps 65\t Score = -55.00000000000004\n",
      "Episode: Steps 66\t Score = -55.83333333333338\n",
      "Episode: Steps 67\t Score = -56.666666666666714\n",
      "Episode: Steps 68\t Score = -57.50000000000005\n",
      "Episode: Steps 69\t Score = -58.333333333333385\n",
      "Episode: Steps 70\t Score = -59.16666666666672\n",
      "Episode: Steps 71\t Score = -60.00000000000006\n",
      "Episode: Steps 72\t Score = -60.83333333333339\n",
      "Episode: Steps 73\t Score = -61.66666666666673\n",
      "Episode: Steps 74\t Score = -62.500000000000064\n",
      "Episode: Steps 75\t Score = -63.3333333333334\n",
      "Episode: Steps 76\t Score = -64.16666666666674\n",
      "Episode: Steps 77\t Score = -65.00000000000007\n",
      "Episode: Steps 78\t Score = -65.8333333333334\n",
      "Episode: Steps 79\t Score = -66.66666666666673\n",
      "Episode: Steps 80\t Score = -67.50000000000006\n",
      "[(43, 11)]\n",
      "Episode: Steps 81\t Score = -68.33333333333339\n",
      "[(43, 11)]\n",
      "[(16, 13)]\n",
      "Episode: Steps 82\t Score = -69.16666666666671\n",
      "[(43, 11)]\n",
      "[(16, 13)]\n",
      "Episode: Steps 83\t Score = -70.00000000000004\n",
      "[(43, 11)]\n",
      "[(16, 13)]\n",
      "Episode: Steps 84\t Score = -70.83333333333337\n",
      "[(16, 13)]\n",
      "Episode: Steps 85\t Score = -71.6666666666667\n",
      "Episode: Steps 86\t Score = -72.50000000000003\n",
      "Episode: Steps 87\t Score = -73.33333333333336\n",
      "Episode: Steps 88\t Score = -74.16666666666669\n",
      "Episode: Steps 89\t Score = -75.00000000000001\n",
      "[(17, 12)]\n",
      "Episode: Steps 90\t Score = -75.83333333333334\n",
      "[(17, 12)]\n",
      "Episode: Steps 91\t Score = -76.66666666666667\n",
      "[(17, 12)]\n",
      "Episode: Steps 92\t Score = -77.5\n",
      "[(17, 12)]\n",
      "Episode: Steps 93\t Score = -78.33333333333333\n",
      "Episode: Steps 94\t Score = -79.16666666666666\n",
      "[(44, 14)]\n",
      "Episode: Steps 95\t Score = -79.99999999999999\n",
      "[(44, 14)]\n",
      "Episode: Steps 96\t Score = -80.83333333333331\n",
      "[(44, 14)]\n",
      "Episode: Steps 97\t Score = -81.66666666666664\n",
      "[(44, 14)]\n",
      "Episode: Steps 98\t Score = -82.49999999999997\n",
      "Episode: Steps 99\t Score = -83.3333333333333\n",
      "Episode: Steps 100\t Score = -84.16666666666663\n",
      "Episode: Steps 101\t Score = -84.99999999999996\n",
      "[(45, 15)]\n",
      "Episode: Steps 102\t Score = -85.83333333333329\n",
      "[(45, 15)]\n",
      "Episode: Steps 103\t Score = -86.66666666666661\n",
      "[(45, 15)]\n",
      "Episode: Steps 104\t Score = -87.49999999999994\n",
      "[(45, 15)]\n",
      "Episode: Steps 105\t Score = -88.33333333333327\n",
      "Episode: Steps 106\t Score = -89.1666666666666\n",
      "[(20, 13)]\n",
      "Episode: Steps 107\t Score = -89.99999999999993\n",
      "[(20, 13)]\n",
      "Episode: Steps 108\t Score = -90.83333333333326\n",
      "[(44, 18)]\n",
      "[(20, 13)]\n",
      "Episode: Steps 109\t Score = -91.66666666666659\n",
      "[(44, 18)]\n",
      "[(20, 13)]\n",
      "Episode: Steps 110\t Score = -92.49999999999991\n",
      "[(44, 18)]\n",
      "Episode: Steps 111\t Score = -93.33333333333324\n",
      "Episode: Steps 112\t Score = -94.16666666666657\n",
      "Episode: Steps 113\t Score = -94.9999999999999\n",
      "Episode: Steps 114\t Score = -95.83333333333323\n",
      "[(44, 20)]\n",
      "Episode: Steps 115\t Score = -96.66666666666656\n",
      "[(44, 20)]\n",
      "Episode: Steps 116\t Score = -97.49999999999989\n",
      "[(44, 20)]\n",
      "Episode: Steps 117\t Score = -98.33333333333321\n",
      "[(44, 20)]\n",
      "Episode: Steps 118\t Score = -99.16666666666654\n",
      "Episode: Steps 119\t Score = -99.99999999999987\n",
      "Episode: Steps 120\t Score = -100.8333333333332\n",
      "Episode: Steps 121\t Score = -101.66666666666653\n",
      "Episode: Steps 122\t Score = -102.49999999999986\n",
      "[(25, 12)]\n",
      "Episode: Steps 123\t Score = -103.33333333333319\n",
      "[(25, 12)]\n",
      "Episode: Steps 124\t Score = -104.16666666666652\n",
      "[(25, 12)]\n",
      "Episode: Steps 125\t Score = -104.99999999999984\n",
      "[(25, 12)]\n",
      "Episode: Steps 126\t Score = -105.83333333333317\n",
      "[(25, 12)]\n",
      "Episode: Steps 127\t Score = -106.6666666666665\n",
      "Episode: Steps 128\t Score = -107.49999999999983\n",
      "Episode: Steps 129\t Score = -108.33333333333316\n",
      "Episode: Steps 130\t Score = -109.16666666666649\n",
      "Episode: Steps 131\t Score = -109.99999999999982\n",
      "Episode: Steps 132\t Score = -110.83333333333314\n",
      "Episode: Steps 133\t Score = -111.66666666666647\n",
      "Episode: Steps 134\t Score = -112.4999999999998\n",
      "Episode: Steps 135\t Score = -113.33333333333313\n",
      "Episode: Steps 136\t Score = -114.16666666666646\n",
      "Episode: Steps 137\t Score = -114.99999999999979\n",
      "Episode: Steps 138\t Score = -115.83333333333312\n",
      "Episode: Steps 139\t Score = -116.66666666666644\n",
      "Episode: Steps 140\t Score = -117.49999999999977\n",
      "Episode: Steps 141\t Score = -118.3333333333331\n",
      "Episode: Steps 142\t Score = -119.16666666666643\n",
      "[(20, 32)]\n",
      "Episode: Steps 143\t Score = -119.99999999999976\n",
      "[(20, 32)]\n",
      "Episode: Steps 144\t Score = -120.83333333333309\n",
      "[(20, 32)]\n",
      "Episode: Steps 145\t Score = -121.66666666666642\n",
      "[(20, 32)]\n",
      "Episode: Steps 146\t Score = -122.49999999999974\n",
      "Episode: Steps 147\t Score = -123.33333333333307\n",
      "Episode: Steps 148\t Score = -124.1666666666664\n",
      "Episode: Steps 149\t Score = -124.99999999999973\n",
      "Episode: Steps 150\t Score = -125.83333333333306\n",
      "Episode: Steps 151\t Score = -126.66666666666639\n",
      "Episode: Steps 152\t Score = -127.49999999999972\n",
      "[(39, 26)]\n",
      "Episode: Steps 153\t Score = -128.33333333333306\n",
      "[(39, 26)]\n",
      "Episode: Steps 154\t Score = -129.1666666666664\n",
      "[(39, 26)]\n",
      "Episode: Steps 155\t Score = -129.99999999999974\n",
      "Episode: Steps 156\t Score = -130.8333333333331\n",
      "Episode: Steps 157\t Score = -131.66666666666643\n",
      "Episode: Steps 158\t Score = -132.49999999999977\n",
      "Episode: Steps 159\t Score = -133.33333333333312\n",
      "[(21, 27)]\n",
      "Episode: Steps 160\t Score = -134.16666666666646\n",
      "[(21, 27)]\n",
      "Episode: Steps 161\t Score = -134.9999999999998\n",
      "[(21, 27)]\n",
      "Episode: Steps 162\t Score = -135.83333333333314\n",
      "[(21, 27)]\n",
      "Episode: Steps 163\t Score = -136.6666666666665\n",
      "Episode: Steps 164\t Score = -137.49999999999983\n",
      "Episode: Steps 165\t Score = -138.33333333333317\n",
      "[(35, 12)]\n",
      "Episode: Steps 166\t Score = -139.16666666666652\n",
      "[(35, 12)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: Steps 167\t Score = -139.99999999999986\n",
      "[(39, 29)]\n",
      "[(35, 12)]\n",
      "Episode: Steps 168\t Score = -140.8333333333332\n",
      "[(39, 29)]\n",
      "[(35, 12)]\n",
      "Episode: Steps 169\t Score = -141.66666666666654\n",
      "[(39, 29)]\n",
      "Episode: Steps 170\t Score = -142.4999999999999\n",
      "Episode: Steps 171\t Score = -143.33333333333323\n",
      "Episode: Steps 172\t Score = -144.16666666666657\n",
      "Episode: Steps 173\t Score = -144.99999999999991\n",
      "Episode: Steps 174\t Score = -145.83333333333326\n",
      "Episode: Steps 175\t Score = -146.6666666666666\n",
      "Episode: Steps 176\t Score = -147.49999999999994\n",
      "Episode: Steps 177\t Score = -148.3333333333333\n",
      "Episode: Steps 178\t Score = -149.16666666666663\n",
      "Episode: Steps 179\t Score = -149.99999999999997\n",
      "Episode: Steps 180\t Score = -150.83333333333331\n",
      "Episode: Steps 181\t Score = -151.66666666666666\n",
      "Episode: Steps 182\t Score = -152.5\n",
      "Episode: Steps 183\t Score = -153.33333333333334\n",
      "Episode: Steps 184\t Score = -154.16666666666669\n",
      "Episode: Steps 185\t Score = -155.00000000000003\n",
      "Episode: Steps 186\t Score = -155.83333333333337\n",
      "Episode: Steps 187\t Score = -156.6666666666667\n",
      "Episode: Steps 188\t Score = -157.50000000000006\n",
      "Episode: Steps 189\t Score = -158.3333333333334\n",
      "Episode: Steps 190\t Score = -159.16666666666674\n",
      "Episode: Steps 191\t Score = -160.00000000000009\n",
      "Episode: Steps 192\t Score = -160.83333333333343\n",
      "Episode: Steps 193\t Score = -161.66666666666677\n",
      "Episode: Steps 194\t Score = -162.5000000000001\n",
      "Episode: Steps 195\t Score = -163.33333333333346\n",
      "Episode: Steps 196\t Score = -164.1666666666668\n",
      "Episode: Steps 197\t Score = -165.00000000000014\n",
      "Episode: Steps 198\t Score = -165.83333333333348\n",
      "Episode: Steps 199\t Score = -166.66666666666683\n",
      "Episode: Steps 200\t Score = -167.50000000000017\n",
      "Episode: Steps 201\t Score = -168.3333333333335\n",
      "Episode: Steps 202\t Score = -169.16666666666686\n",
      "Episode: Steps 203\t Score = -170.0000000000002\n",
      "Episode: Steps 204\t Score = -170.83333333333354\n",
      "Episode: Steps 205\t Score = -171.66666666666688\n",
      "Episode: Steps 206\t Score = -172.50000000000023\n",
      "Episode: Steps 207\t Score = -173.33333333333357\n",
      "Episode: Steps 208\t Score = -174.1666666666669\n",
      "Episode: Steps 209\t Score = -175.00000000000026\n",
      "Episode: Steps 210\t Score = -175.8333333333336\n",
      "Episode: Steps 211\t Score = -176.66666666666694\n",
      "Episode: Steps 212\t Score = -177.50000000000028\n",
      "Episode: Steps 213\t Score = -178.33333333333363\n",
      "[(17, 19)]\n",
      "Episode: Steps 214\t Score = -179.16666666666697\n",
      "[(17, 19)]\n",
      "[(43, 11)]\n",
      "Episode: Steps 215\t Score = -180.0000000000003\n",
      "[(17, 19)]\n",
      "[(43, 11)]\n",
      "Episode: Steps 216\t Score = -180.83333333333366\n",
      "[(17, 19)]\n",
      "[(43, 11)]\n",
      "Episode: Steps 217\t Score = -181.666666666667\n",
      "[(43, 11)]\n",
      "Episode: Steps 218\t Score = -182.50000000000034\n",
      "Episode: Steps 219\t Score = -183.33333333333368\n",
      "Episode: Steps 220\t Score = -184.16666666666703\n",
      "Episode: Steps 221\t Score = -185.00000000000037\n",
      "Episode: Steps 222\t Score = -185.8333333333337\n",
      "Episode: Steps 223\t Score = -186.66666666666706\n",
      "Episode: Steps 224\t Score = -187.5000000000004\n",
      "Episode: Steps 225\t Score = -188.33333333333374\n",
      "Episode: Steps 226\t Score = -189.16666666666708\n",
      "Episode: Steps 227\t Score = -190.00000000000043\n",
      "Episode: Steps 228\t Score = -190.83333333333377\n",
      "Episode: Steps 229\t Score = -191.6666666666671\n",
      "Episode: Steps 230\t Score = -192.50000000000045\n",
      "Episode: Steps 231\t Score = -193.3333333333338\n",
      "Episode: Steps 232\t Score = -194.16666666666714\n",
      "[(31, 41)]\n",
      "Episode: Steps 233\t Score = -195.00000000000048\n",
      "[(31, 41)]\n",
      "Episode: Steps 234\t Score = -195.83333333333383\n",
      "[(31, 41)]\n",
      "[(41, 14)]\n",
      "Episode: Steps 235\t Score = -196.66666666666717\n",
      "[(31, 41)]\n",
      "[(41, 14)]\n",
      "Episode: Steps 236\t Score = -197.5000000000005\n",
      "[(41, 14)]\n",
      "Episode: Steps 237\t Score = -198.33333333333385\n",
      "[(41, 14)]\n",
      "Episode: Steps 238\t Score = -199.1666666666672\n",
      "[(41, 14)]\n",
      "Episode: Steps 239\t Score = -200.00000000000054\n",
      "[(41, 14)]\n",
      "Episode: Steps 240\t Score = -200.83333333333388\n",
      "Episode: Steps 241\t Score = -201.66666666666723\n",
      "[(16, 13)]\n",
      "Episode: Steps 242\t Score = -202.50000000000057\n",
      "[(16, 13)]\n",
      "Episode: Steps 243\t Score = -203.3333333333339\n",
      "[(16, 13)]\n",
      "Episode: Steps 244\t Score = -204.16666666666725\n",
      "[(16, 13)]\n",
      "Episode: Steps 245\t Score = -205.0000000000006\n",
      "[(16, 13)]\n",
      "Episode: Steps 246\t Score = -205.83333333333394\n",
      "Episode: Steps 247\t Score = -206.66666666666728\n",
      "Episode: Steps 248\t Score = -207.50000000000063\n",
      "Episode: Steps 249\t Score = -208.33333333333397\n",
      "Episode: Steps 250\t Score = -209.1666666666673\n",
      "[(17, 12)]\n",
      "Episode: Steps 251\t Score = -210.00000000000065\n",
      "[(17, 12)]\n",
      "Episode: Steps 252\t Score = -210.833333333334\n",
      "[(17, 12)]\n",
      "[(42, 19)]\n",
      "Episode: Steps 253\t Score = -211.66666666666734\n",
      "[(17, 12)]\n",
      "[(42, 19)]\n",
      "Episode: Steps 254\t Score = -212.50000000000068\n",
      "[(42, 19)]\n",
      "Episode: Steps 255\t Score = -213.33333333333402\n",
      "[(42, 19)]\n",
      "Episode: Steps 256\t Score = -214.16666666666737\n",
      "Episode: Steps 257\t Score = -215.0000000000007\n",
      "Episode: Steps 258\t Score = -215.83333333333405\n",
      "Episode: Steps 259\t Score = -216.6666666666674\n",
      "Episode: Steps 260\t Score = -217.50000000000074\n",
      "Episode: Steps 261\t Score = -218.33333333333408\n",
      "Episode: Steps 262\t Score = -219.16666666666742\n",
      "Episode: Steps 263\t Score = -220.00000000000077\n",
      "Episode: Steps 264\t Score = -220.8333333333341\n",
      "Episode: Steps 265\t Score = -221.66666666666745\n",
      "Episode: Steps 266\t Score = -222.5000000000008\n",
      "Episode: Steps 267\t Score = -223.33333333333414\n",
      "Episode: Steps 268\t Score = -224.16666666666748\n",
      "Episode: Steps 269\t Score = -225.00000000000082\n",
      "Episode: Steps 270\t Score = -225.83333333333417\n",
      "Episode: Steps 271\t Score = -226.6666666666675\n",
      "Episode: Steps 272\t Score = -227.50000000000085\n",
      "Episode: Steps 273\t Score = -228.3333333333342\n",
      "[(20, 10)]\n",
      "Episode: Steps 274\t Score = -229.16666666666754\n",
      "[(20, 10)]\n",
      "Episode: Steps 275\t Score = -230.00000000000088\n",
      "[(20, 10)]\n",
      "Episode: Steps 276\t Score = -230.83333333333422\n",
      "[(20, 10)]\n",
      "Episode: Steps 277\t Score = -231.66666666666757\n",
      "[(20, 10)]\n",
      "Episode: Steps 278\t Score = -232.5000000000009\n",
      "Episode: Steps 279\t Score = -233.33333333333425\n",
      "Episode: Steps 280\t Score = -234.1666666666676\n",
      "Episode: Steps 281\t Score = -235.00000000000094\n",
      "Episode: Steps 282\t Score = -235.83333333333428\n",
      "Episode: Steps 283\t Score = -236.66666666666762\n",
      "Episode: Steps 284\t Score = -237.50000000000097\n",
      "Episode: Steps 285\t Score = -238.3333333333343\n",
      "Episode: Steps 286\t Score = -239.16666666666765\n",
      "Episode: Steps 287\t Score = -240.000000000001\n",
      "Episode: Steps 288\t Score = -240.83333333333434\n",
      "Episode: Steps 289\t Score = -241.66666666666768\n",
      "Episode: Steps 290\t Score = -242.50000000000102\n",
      "Episode: Steps 291\t Score = -243.33333333333437\n",
      "Episode: Steps 292\t Score = -244.1666666666677\n",
      "[(25, 11)]\n",
      "Episode: Steps 293\t Score = -245.00000000000105\n",
      "[(25, 11)]\n",
      "Episode: Steps 294\t Score = -245.8333333333344\n",
      "[(25, 11)]\n",
      "Episode: Steps 295\t Score = -246.66666666666774\n",
      "[(25, 11)]\n",
      "Episode: Steps 296\t Score = -247.50000000000108\n",
      "[(20, 32)]\n",
      "Episode: Steps 297\t Score = -248.33333333333442\n",
      "[(20, 32)]\n",
      "Episode: Steps 298\t Score = -249.16666666666777\n",
      "[(20, 32)]\n",
      "Episode: Steps 299\t Score = -250.0000000000011\n",
      "Episode: Steps 300\t Score = -250.83333333333445\n",
      "Episode: Steps 301\t Score = -251.6666666666678\n",
      "Episode: Steps 302\t Score = -252.50000000000114\n",
      "[(40, 27)]\n",
      "Episode: Steps 303\t Score = -253.33333333333448\n",
      "[(40, 27)]\n",
      "Episode: Steps 304\t Score = -254.16666666666782\n",
      "[(40, 27)]\n",
      "Episode: Steps 305\t Score = -255.00000000000117\n",
      "[(40, 27)]\n",
      "Episode: Steps 306\t Score = -255.8333333333345\n",
      "Episode: Steps 307\t Score = -256.6666666666678\n",
      "Episode: Steps 308\t Score = -257.50000000000114\n",
      "Episode: Steps 309\t Score = -258.33333333333445\n",
      "Episode: Steps 310\t Score = -259.16666666666777\n",
      "Episode: Steps 311\t Score = -260.0000000000011\n",
      "[(21, 27)]\n",
      "Episode: Steps 312\t Score = -260.8333333333344\n",
      "[(21, 27)]\n",
      "Episode: Steps 313\t Score = -261.6666666666677\n",
      "[(21, 27)]\n",
      "Episode: Steps 314\t Score = -262.500000000001\n",
      "Episode: Steps 315\t Score = -263.33333333333434\n",
      "Episode: Steps 316\t Score = -264.16666666666765\n",
      "Episode: Steps 317\t Score = -265.00000000000097\n",
      "Episode: Steps 318\t Score = -265.8333333333343\n",
      "Episode: Steps 319\t Score = -266.6666666666676\n",
      "Episode: Steps 320\t Score = -267.5000000000009\n",
      "Episode: Steps 321\t Score = -268.3333333333342\n",
      "Episode: Steps 322\t Score = -269.16666666666754\n",
      "Episode: Steps 323\t Score = -270.00000000000085\n",
      "Episode: Steps 324\t Score = -270.83333333333417\n",
      "Episode: Steps 325\t Score = -271.6666666666675\n",
      "[(39, 29)]\n",
      "Episode: Steps 326\t Score = -272.5000000000008\n",
      "[(39, 29)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: Steps 327\t Score = -273.3333333333341\n",
      "[(39, 29)]\n",
      "Episode: Steps 328\t Score = -274.1666666666674\n",
      "[(39, 29)]\n",
      "Episode: Steps 329\t Score = -275.00000000000074\n",
      "Episode: Steps 330\t Score = -275.83333333333405\n",
      "Episode: Steps 331\t Score = -276.66666666666737\n",
      "Episode: Steps 332\t Score = -277.5000000000007\n",
      "Episode: Steps 333\t Score = -278.333333333334\n",
      "[(34, 11)]\n",
      "Episode: Steps 334\t Score = -279.1666666666673\n",
      "[(34, 11)]\n",
      "Episode: Steps 335\t Score = -280.0000000000006\n",
      "[(34, 11)]\n",
      "Episode: Steps 336\t Score = -280.83333333333394\n",
      "[(34, 11)]\n",
      "Episode: Steps 337\t Score = -281.66666666666725\n",
      "Episode: Steps 338\t Score = -282.50000000000057\n",
      "Episode: Steps 339\t Score = -283.3333333333339\n",
      "Episode: Steps 340\t Score = -284.1666666666672\n",
      "Episode: Steps 341\t Score = -285.0000000000005\n",
      "Episode: Steps 342\t Score = -285.8333333333338\n",
      "Episode: Steps 343\t Score = -286.66666666666714\n",
      "Episode: Steps 344\t Score = -287.50000000000045\n",
      "Episode: Steps 345\t Score = -288.33333333333377\n",
      "Episode: Steps 346\t Score = -289.1666666666671\n",
      "Episode: Steps 347\t Score = -290.0000000000004\n",
      "Episode: Steps 348\t Score = -290.8333333333337\n",
      "Episode: Steps 349\t Score = -291.666666666667\n",
      "[(18, 18)]\n",
      "Episode: Steps 350\t Score = -292.50000000000034\n",
      "[(18, 18)]\n",
      "Episode: Steps 351\t Score = -293.33333333333366\n",
      "[(18, 18)]\n",
      "Episode: Steps 352\t Score = -294.16666666666697\n",
      "Episode: Steps 353\t Score = -295.0000000000003\n",
      "Episode: Steps 354\t Score = -295.8333333333336\n",
      "Episode: Steps 355\t Score = -296.6666666666669\n",
      "Episode: Steps 356\t Score = -297.5000000000002\n",
      "Episode: Steps 357\t Score = -298.33333333333354\n",
      "Episode: Steps 358\t Score = -299.16666666666686\n",
      "Episode: Steps 359\t Score = -300.00000000000017\n",
      "Episode: Steps 360\t Score = -300.8333333333335\n",
      "Episode: Steps 361\t Score = -301.6666666666668\n",
      "Episode: Steps 362\t Score = -302.5000000000001\n",
      "Episode: Steps 363\t Score = -303.3333333333334\n",
      "Episode: Steps 364\t Score = -304.16666666666674\n",
      "Episode: Steps 365\t Score = -305.00000000000006\n",
      "Episode: Steps 366\t Score = -305.83333333333337\n",
      "Episode: Steps 367\t Score = -306.6666666666667\n",
      "Episode: Steps 368\t Score = -307.5\n",
      "Episode: Steps 369\t Score = -308.3333333333333\n",
      "Episode: Steps 370\t Score = -309.16666666666663\n",
      "Episode: Steps 371\t Score = -309.99999999999994\n",
      "Episode: Steps 372\t Score = -310.83333333333326\n",
      "[(16, 13)]\n",
      "Episode: Steps 373\t Score = -311.6666666666666\n",
      "[(16, 13)]\n",
      "Episode: Steps 374\t Score = -312.4999999999999\n",
      "[(16, 13)]\n",
      "Episode: Steps 375\t Score = -313.3333333333332\n",
      "[(16, 13)]\n",
      "Episode: Steps 376\t Score = -314.1666666666665\n",
      "Episode: Steps 377\t Score = -314.99999999999983\n",
      "Episode: Steps 378\t Score = -315.83333333333314\n",
      "Episode: Steps 379\t Score = -316.66666666666646\n",
      "[(17, 12)]\n",
      "Episode: Steps 380\t Score = -317.4999999999998\n",
      "[(17, 12)]\n",
      "Episode: Steps 381\t Score = -318.3333333333331\n",
      "[(43, 11)]\n",
      "[(17, 12)]\n",
      "Episode: Steps 382\t Score = -319.1666666666664\n",
      "[(43, 11)]\n",
      "Episode: Steps 383\t Score = -319.9999999999997\n",
      "[(43, 11)]\n",
      "Episode: Steps 384\t Score = -320.83333333333303\n",
      "[(43, 11)]\n",
      "Episode: Steps 385\t Score = -321.66666666666634\n",
      "Episode: Steps 386\t Score = -322.49999999999966\n",
      "Episode: Steps 387\t Score = -323.333333333333\n",
      "Episode: Steps 388\t Score = -324.1666666666663\n",
      "Episode: Steps 389\t Score = -324.9999999999996\n",
      "Episode: Steps 390\t Score = -325.8333333333329\n",
      "Episode: Steps 391\t Score = -326.66666666666623\n",
      "Episode: Steps 392\t Score = -327.49999999999955\n",
      "Episode: Steps 393\t Score = -328.33333333333286\n",
      "Episode: Steps 394\t Score = -329.1666666666662\n",
      "[(20, 10)]\n",
      "Episode: Steps 395\t Score = -329.9999999999995\n",
      "[(20, 10)]\n",
      "Episode: Steps 396\t Score = -330.8333333333328\n",
      "[(20, 10)]\n",
      "Episode: Steps 397\t Score = -331.6666666666661\n",
      "[(44, 14)]\n",
      "Episode: Steps 398\t Score = -332.49999999999943\n",
      "[(44, 14)]\n",
      "Episode: Steps 399\t Score = -333.33333333333275\n",
      "[(44, 14)]\n",
      "Episode: Steps 400\t Score = -334.16666666666606\n",
      "[(44, 14)]\n",
      "Episode: Steps 401\t Score = -334.9999999999994\n",
      "Episode: Steps 402\t Score = -335.8333333333327\n",
      "Episode: Steps 403\t Score = -336.666666666666\n",
      "Episode: Steps 404\t Score = -337.4999999999993\n",
      "Episode: Steps 405\t Score = -338.33333333333263\n",
      "Episode: Steps 406\t Score = -339.16666666666595\n",
      "Episode: Steps 407\t Score = -339.99999999999926\n",
      "Episode: Steps 408\t Score = -340.8333333333326\n",
      "[(25, 11)]\n",
      "Episode: Steps 409\t Score = -341.6666666666659\n",
      "[(25, 11)]\n",
      "Episode: Steps 410\t Score = -342.4999999999992\n",
      "[(25, 11)]\n",
      "[(31, 41)]\n",
      "Episode: Steps 411\t Score = -343.3333333333325\n",
      "[(25, 11)]\n",
      "[(31, 41)]\n",
      "Episode: Steps 412\t Score = -344.16666666666583\n",
      "[(31, 41)]\n",
      "Episode: Steps 413\t Score = -344.99999999999915\n",
      "[(31, 41)]\n",
      "Episode: Steps 414\t Score = -345.83333333333246\n",
      "[(43, 19)]\n",
      "Episode: Steps 415\t Score = -346.6666666666658\n",
      "[(43, 19)]\n",
      "Episode: Steps 416\t Score = -347.4999999999991\n",
      "[(43, 19)]\n",
      "Episode: Steps 417\t Score = -348.3333333333324\n",
      "[(43, 19)]\n",
      "Episode: Steps 418\t Score = -349.1666666666657\n",
      "Episode: Steps 419\t Score = -349.99999999999903\n",
      "Episode: Steps 420\t Score = -350.83333333333235\n",
      "Episode: Steps 421\t Score = -351.66666666666566\n",
      "Episode: Steps 422\t Score = -352.499999999999\n",
      "Episode: Steps 423\t Score = -353.3333333333323\n",
      "Episode: Steps 424\t Score = -354.1666666666656\n",
      "Episode: Steps 425\t Score = -354.9999999999989\n",
      "Episode: Steps 426\t Score = -355.83333333333223\n",
      "Episode: Steps 427\t Score = -356.66666666666555\n",
      "Episode: Steps 428\t Score = -357.49999999999886\n",
      "Episode: Steps 429\t Score = -358.3333333333322\n",
      "Episode: Steps 430\t Score = -359.1666666666655\n",
      "Episode: Steps 431\t Score = -359.9999999999988\n",
      "Episode: Steps 432\t Score = -360.8333333333321\n",
      "Episode: Steps 433\t Score = -361.66666666666544\n",
      "Episode: Steps 434\t Score = -362.49999999999875\n",
      "Episode: Steps 435\t Score = -363.33333333333206\n",
      "Episode: Steps 436\t Score = -364.1666666666654\n",
      "Episode: Steps 437\t Score = -364.9999999999987\n",
      "Episode: Steps 438\t Score = -365.833333333332\n",
      "Episode: Steps 439\t Score = -366.6666666666653\n",
      "[(34, 10)]\n",
      "Episode: Steps 440\t Score = -367.49999999999864\n",
      "[(34, 10)]\n",
      "Episode: Steps 441\t Score = -368.33333333333195\n",
      "[(34, 10)]\n",
      "Episode: Steps 442\t Score = -369.16666666666526\n",
      "[(34, 10)]\n",
      "Episode: Steps 443\t Score = -369.9999999999986\n",
      "Episode: Steps 444\t Score = -370.8333333333319\n",
      "Episode: Steps 445\t Score = -371.6666666666652\n",
      "Episode: Steps 446\t Score = -372.4999999999985\n",
      "Episode: Steps 447\t Score = -373.33333333333184\n",
      "Episode: Steps 448\t Score = -374.16666666666515\n",
      "Episode: Steps 449\t Score = -374.99999999999847\n",
      "Episode: Steps 450\t Score = -375.8333333333318\n",
      "Episode: Steps 451\t Score = -376.6666666666651\n",
      "Episode: Steps 452\t Score = -377.4999999999984\n",
      "Episode: Steps 453\t Score = -378.3333333333317\n",
      "Episode: Steps 454\t Score = -379.16666666666504\n",
      "Episode: Steps 455\t Score = -379.99999999999835\n",
      "Episode: Steps 456\t Score = -380.83333333333167\n",
      "Episode: Steps 457\t Score = -381.666666666665\n",
      "Episode: Steps 458\t Score = -382.4999999999983\n",
      "Episode: Steps 459\t Score = -383.3333333333316\n",
      "Episode: Steps 460\t Score = -384.1666666666649\n",
      "Episode: Steps 461\t Score = -384.99999999999824\n",
      "Episode: Steps 462\t Score = -385.83333333333155\n",
      "Episode: Steps 463\t Score = -386.66666666666487\n",
      "Episode: Steps 464\t Score = -387.4999999999982\n",
      "Episode: Steps 465\t Score = -388.3333333333315\n",
      "Episode: Steps 466\t Score = -389.1666666666648\n",
      "[(40, 27)]\n",
      "Episode: Steps 467\t Score = -389.9999999999981\n",
      "[(40, 27)]\n",
      "Episode: Steps 468\t Score = -390.83333333333144\n",
      "[(40, 27)]\n",
      "[(23, 36)]\n",
      "Episode: Steps 469\t Score = -391.66666666666475\n",
      "[(40, 27)]\n",
      "[(23, 36)]\n",
      "Episode: Steps 470\t Score = -392.49999999999807\n",
      "[(23, 36)]\n",
      "Episode: Steps 471\t Score = -393.3333333333314\n",
      "[(23, 36)]\n",
      "Episode: Steps 472\t Score = -394.1666666666647\n",
      "[(43, 11)]\n",
      "[(23, 36)]\n",
      "Episode: Steps 473\t Score = -394.999999999998\n",
      "[(43, 11)]\n",
      "Episode: Steps 474\t Score = -395.8333333333313\n",
      "[(43, 11)]\n",
      "Episode: Steps 475\t Score = -396.66666666666464\n",
      "Episode: Steps 476\t Score = -397.49999999999795\n",
      "Episode: Steps 477\t Score = -398.33333333333127\n",
      "[(22, 35)]\n",
      "Episode: Steps 478\t Score = -399.1666666666646\n",
      "[(22, 35)]\n",
      "Episode: Steps 479\t Score = -399.9999999999979\n",
      "[(22, 35)]\n",
      "Episode: Steps 480\t Score = -400.8333333333312\n",
      "[(22, 35)]\n",
      "Episode: Steps 481\t Score = -401.6666666666645\n",
      "Episode: Steps 482\t Score = -402.49999999999784\n",
      "Episode: Steps 483\t Score = -403.33333333333115\n",
      "Episode: Steps 484\t Score = -404.16666666666447\n",
      "Episode: Steps 485\t Score = -404.9999999999978\n",
      "Episode: Steps 486\t Score = -405.8333333333311\n",
      "Episode: Steps 487\t Score = -406.6666666666644\n",
      "[(41, 14)]\n",
      "Episode: Steps 488\t Score = -407.4999999999977\n",
      "[(39, 29)]\n",
      "[(41, 14)]\n",
      "Episode: Steps 489\t Score = -408.33333333333104\n",
      "[(39, 29)]\n",
      "[(41, 14)]\n",
      "Episode: Steps 490\t Score = -409.16666666666436\n",
      "[(39, 29)]\n",
      "Episode: Steps 491\t Score = -409.99999999999767\n",
      "[(39, 29)]\n",
      "Episode: Steps 492\t Score = -410.833333333331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: Steps 493\t Score = -411.6666666666643\n",
      "[(40, 15)]\n",
      "[(23, 32)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-21-9c421b12461c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mnext_obs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mall_rewards\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv_renderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender_env\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshow_observations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshow_inactive_agents\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshow_predictions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_image\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m     \u001B[0mframes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0mframe_step\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/flatland/utils/rendertools.py\u001B[0m in \u001B[0;36mrender_env\u001B[0;34m(self, show, show_agents, show_inactive_agents, show_observations, show_predictions, show_rowcols, frames, episode, step, selected_agent, return_image)\u001B[0m\n\u001B[1;32m     60\u001B[0m                    \u001B[0mselected_agent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# indicate which agent is \"selected\" in the editor):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m                    return_image=False): # indicate if image is returned for use in monitor:\n\u001B[0;32m---> 62\u001B[0;31m         return self.renderer.render_env(show, show_agents, show_inactive_agents, show_observations,\n\u001B[0m\u001B[1;32m     63\u001B[0m                     show_predictions, show_rowcols, frames, episode, step, selected_agent, return_image)\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/flatland/utils/rendertools.py\u001B[0m in \u001B[0;36mrender_env\u001B[0;34m(self, show, show_agents, show_inactive_agents, show_observations, show_predictions, show_rowcols, frames, episode, step, selected_agent, return_image)\u001B[0m\n\u001B[1;32m    524\u001B[0m         \u001B[0;31m# if type(self.gl) is PILSVG:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    525\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgl_str\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"PILSVG\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"PGL\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 526\u001B[0;31m             return self.render_env_svg(show=show,\n\u001B[0m\u001B[1;32m    527\u001B[0m                                 \u001B[0mshow_observations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshow_observations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m                                 \u001B[0mshow_predictions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshow_predictions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/flatland/utils/rendertools.py\u001B[0m in \u001B[0;36mrender_env_svg\u001B[0;34m(self, show, show_observations, show_predictions, selected_agent, show_agents, show_inactive_agents, show_rowcols, return_image)\u001B[0m\n\u001B[1;32m    759\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    760\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mshow\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 761\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    762\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    763\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_events\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/flatland/utils/graphics_pgl.py\u001B[0m in \u001B[0;36mshow\u001B[0;34m(self, block, from_event)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0mpil_img\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malpha_composite_layers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0mpil_img_resized\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpil_img\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwindow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwidth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwindow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresample\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNEAREST\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0;31m# convert our PIL image to pyglet:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mresize\u001B[0;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[1;32m   1910\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1911\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"LA\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"RGBA\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1912\u001B[0;31m             \u001B[0mim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"a\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1913\u001B[0m             \u001B[0mim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbox\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1914\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/rl-on-trains-workshop/venv/lib/python3.8/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m   1024\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1026\u001B[0;31m             \u001B[0mim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdither\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1027\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1028\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for step in range(500):\n",
    "    # Chose an action for each agent in the environment\n",
    "    for a in range(env.get_num_agents()):\n",
    "        action = controller.act(observations[a])\n",
    "        action_dict.update({a: action})\n",
    "\n",
    "    # Environment step which returns the observations for all agents, their corresponding\n",
    "    # reward and whether their are done\n",
    "\n",
    "    next_obs, all_rewards, done, _ = env.step(action_dict)\n",
    "\n",
    "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
    "    frames.append(frame)\n",
    "    frame_step += 1\n",
    "    # Update replay buffer and train agent\n",
    "    for a in range(env.get_num_agents()):\n",
    "        controller.step((observations[a], action_dict[a], all_rewards[a], next_obs[a], done[a]))\n",
    "        score += all_rewards[a]\n",
    "\n",
    "    observations = next_obs.copy()\n",
    "    if done['__all__']:\n",
    "        break\n",
    "    print('Episode: Steps {}\\t Score = {}'.format(step, score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our helper function `display_episode` allows us to get an animated episode. By putting `%%capture` at the begining of the cell we can surpress the cell output and create a clean output in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "animation = display_episode(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "animation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPTWnz5Rx3m1urg+rY7OeXP",
   "include_colab_link": true,
   "name": "01 Intro to environment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}